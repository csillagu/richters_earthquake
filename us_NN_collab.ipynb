{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rs4ycvG2azx7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRhdeOGHnDvV",
        "outputId": "de01bbca-fa89-45ae-aa01-852317353d65"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, Input\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Jnw43CKdbRom"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "cY3OWGBwcLQ9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "_t2YsHu7m8Lk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "giLDsZ_ZnG3d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "QKTfY8W0nLlr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = pd.read_csv(\"/content/drive/MyDrive/DataDcience/train_labels_preprocessed.csv\")\n",
        "train_values = pd.read_csv(\"/content/drive/MyDrive/DataDcience/train_values_preprocessed.csv\")"
      ],
      "metadata": {
        "id": "MbhhayhcbYpR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels.drop(labels=['Unnamed: 0'],axis=1,inplace=True)\n",
        "train_labels.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eLwHP9HblEvQ",
        "outputId": "7565e58d-6f1c-4c4d-9e85-c20aa589d017"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   damage_grade\n",
              "0             3\n",
              "1             2\n",
              "2             3\n",
              "3             2\n",
              "4             3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d58cf97c-3cf2-49de-8d6a-bda5b75a9264\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>damage_grade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d58cf97c-3cf2-49de-8d6a-bda5b75a9264')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d58cf97c-3cf2-49de-8d6a-bda5b75a9264 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d58cf97c-3cf2-49de-8d6a-bda5b75a9264');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels[\"damage_grade\"] = train_labels[\"damage_grade\"] - 1\n",
        "train_labels.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "POH_hpe4w01v",
        "outputId": "343bab47-03d8-4d43-f66f-cae653387ae3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   damage_grade\n",
              "0             2\n",
              "1             1\n",
              "2             2\n",
              "3             1\n",
              "4             2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a0064fd-00f4-4967-8fdd-c8d43a1c6ebc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>damage_grade</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a0064fd-00f4-4967-8fdd-c8d43a1c6ebc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a0064fd-00f4-4967-8fdd-c8d43a1c6ebc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a0064fd-00f4-4967-8fdd-c8d43a1c6ebc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "train_labels = to_categorical(train_labels, 3)"
      ],
      "metadata": {
        "id": "SdyrWuditCWj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq74xaEBvysQ",
        "outputId": "c3aa76f9-9155-4c9c-953d-232d81325f3a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_values.drop(labels=['Unnamed: 0'],axis=1,inplace=True)\n",
        "train_values.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "0lnnJADKlHvY",
        "outputId": "a824dfa3-7291-4f72-95b2-6bd8fd21e4f5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   geo_level_1_id  geo_level_2_id  geo_level_3_id  count_floors_pre_eq  \\\n",
              "0               6             487           12198                    2   \n",
              "1               8             900            2812                    2   \n",
              "2              21             363            8973                    2   \n",
              "3              22             418           10694                    2   \n",
              "4              11             131            1488                    3   \n",
              "\n",
              "        age  area_percentage  height_percentage  has_superstructure_adobe_mud  \\\n",
              "0  0.500000         0.357143           0.428571                             1   \n",
              "1  0.166667         0.500000           0.714286                             0   \n",
              "2  0.166667         0.285714           0.428571                             0   \n",
              "3  0.166667         0.357143           0.428571                             0   \n",
              "4  0.500000         0.500000           1.000000                             1   \n",
              "\n",
              "   has_superstructure_mud_mortar_stone  has_superstructure_stone_flag  ...  \\\n",
              "0                                    1                              0  ...   \n",
              "1                                    1                              0  ...   \n",
              "2                                    1                              0  ...   \n",
              "3                                    1                              0  ...   \n",
              "4                                    0                              0  ...   \n",
              "\n",
              "   plan_configuration_f  plan_configuration_m  plan_configuration_n  \\\n",
              "0                     0                     0                     0   \n",
              "1                     0                     0                     0   \n",
              "2                     0                     0                     0   \n",
              "3                     0                     0                     0   \n",
              "4                     0                     0                     0   \n",
              "\n",
              "   plan_configuration_o  plan_configuration_q  plan_configuration_s  \\\n",
              "0                     0                     0                     0   \n",
              "1                     0                     0                     0   \n",
              "2                     0                     0                     0   \n",
              "3                     0                     0                     0   \n",
              "4                     0                     0                     0   \n",
              "\n",
              "   plan_configuration_u  legal_ownership_status_r  legal_ownership_status_v  \\\n",
              "0                     0                         0                         1   \n",
              "1                     0                         0                         1   \n",
              "2                     0                         0                         1   \n",
              "3                     0                         0                         1   \n",
              "4                     0                         0                         1   \n",
              "\n",
              "   legal_ownership_status_w  \n",
              "0                         0  \n",
              "1                         0  \n",
              "2                         0  \n",
              "3                         0  \n",
              "4                         0  \n",
              "\n",
              "[5 rows x 60 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-533cde49-a3c7-4459-a136-6410c20962cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>geo_level_1_id</th>\n",
              "      <th>geo_level_2_id</th>\n",
              "      <th>geo_level_3_id</th>\n",
              "      <th>count_floors_pre_eq</th>\n",
              "      <th>age</th>\n",
              "      <th>area_percentage</th>\n",
              "      <th>height_percentage</th>\n",
              "      <th>has_superstructure_adobe_mud</th>\n",
              "      <th>has_superstructure_mud_mortar_stone</th>\n",
              "      <th>has_superstructure_stone_flag</th>\n",
              "      <th>...</th>\n",
              "      <th>plan_configuration_f</th>\n",
              "      <th>plan_configuration_m</th>\n",
              "      <th>plan_configuration_n</th>\n",
              "      <th>plan_configuration_o</th>\n",
              "      <th>plan_configuration_q</th>\n",
              "      <th>plan_configuration_s</th>\n",
              "      <th>plan_configuration_u</th>\n",
              "      <th>legal_ownership_status_r</th>\n",
              "      <th>legal_ownership_status_v</th>\n",
              "      <th>legal_ownership_status_w</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>487</td>\n",
              "      <td>12198</td>\n",
              "      <td>2</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>900</td>\n",
              "      <td>2812</td>\n",
              "      <td>2</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>21</td>\n",
              "      <td>363</td>\n",
              "      <td>8973</td>\n",
              "      <td>2</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22</td>\n",
              "      <td>418</td>\n",
              "      <td>10694</td>\n",
              "      <td>2</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>131</td>\n",
              "      <td>1488</td>\n",
              "      <td>3</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 60 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-533cde49-a3c7-4459-a136-6410c20962cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-533cde49-a3c7-4459-a136-6410c20962cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-533cde49-a3c7-4459-a136-6410c20962cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_values, train_labels, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "94zoF50zbTUe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Input(shape = (60)),\n",
        "    Dense(128, activation='relu', use_bias=False),\n",
        "    Dense(256, activation='relu', use_bias=False),\n",
        "    Dense(128, activation='relu', use_bias=False),\n",
        "    Dense(64, activation='relu', use_bias=False),\n",
        "    Dense(3, activation='softmax', use_bias=False)\n",
        "]) \n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fb1ghuwRbXbl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping=EarlyStopping(patience=16, verbose=1)\n",
        "\n",
        "checkpointer=ModelCheckpoint(filepath='weights.hdf5', save_best_only=True, verbose=1)\n",
        "\n",
        "start_time = time.time()\n",
        "network_history = model.fit(X_train, y_train, batch_size=64, \n",
        "                            epochs=100, verbose=1, validation_split=0.2,\n",
        "                  callbacks=[checkpointer, early_stopping])\n",
        "dt_time_fit = time.time() - start_time"
      ],
      "metadata": {
        "id": "S5bt3ODob_Xz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca77affa-3cbc-4432-80da-da6a6b86ee57"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2605/2606 [============================>.] - ETA: 0s - loss: 2.5791 - accuracy: 0.4922\n",
            "Epoch 1: val_loss improved from inf to 0.95975, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 14s 5ms/step - loss: 2.5785 - accuracy: 0.4922 - val_loss: 0.9598 - val_accuracy: 0.5672\n",
            "Epoch 2/100\n",
            "2606/2606 [==============================] - ETA: 0s - loss: 0.9432 - accuracy: 0.5329\n",
            "Epoch 2: val_loss improved from 0.95975 to 0.94369, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.9432 - accuracy: 0.5329 - val_loss: 0.9437 - val_accuracy: 0.5661\n",
            "Epoch 3/100\n",
            "2601/2606 [============================>.] - ETA: 0s - loss: 0.8921 - accuracy: 0.5577\n",
            "Epoch 3: val_loss improved from 0.94369 to 0.86459, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.8919 - accuracy: 0.5577 - val_loss: 0.8646 - val_accuracy: 0.5706\n",
            "Epoch 4/100\n",
            "2598/2606 [============================>.] - ETA: 0s - loss: 0.8746 - accuracy: 0.5624\n",
            "Epoch 4: val_loss improved from 0.86459 to 0.84328, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 15s 6ms/step - loss: 0.8745 - accuracy: 0.5624 - val_loss: 0.8433 - val_accuracy: 0.5680\n",
            "Epoch 5/100\n",
            "2603/2606 [============================>.] - ETA: 0s - loss: 0.8385 - accuracy: 0.5697\n",
            "Epoch 5: val_loss improved from 0.84328 to 0.82198, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.8385 - accuracy: 0.5698 - val_loss: 0.8220 - val_accuracy: 0.5710\n",
            "Epoch 6/100\n",
            "2602/2606 [============================>.] - ETA: 0s - loss: 0.8315 - accuracy: 0.5699\n",
            "Epoch 6: val_loss did not improve from 0.82198\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.8315 - accuracy: 0.5699 - val_loss: 0.8246 - val_accuracy: 0.5697\n",
            "Epoch 7/100\n",
            "2606/2606 [==============================] - ETA: 0s - loss: 0.8252 - accuracy: 0.5712\n",
            "Epoch 7: val_loss improved from 0.82198 to 0.81617, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.8252 - accuracy: 0.5712 - val_loss: 0.8162 - val_accuracy: 0.5726\n",
            "Epoch 8/100\n",
            "2600/2606 [============================>.] - ETA: 0s - loss: 0.8223 - accuracy: 0.5721\n",
            "Epoch 8: val_loss did not improve from 0.81617\n",
            "2606/2606 [==============================] - 12s 4ms/step - loss: 0.8223 - accuracy: 0.5719 - val_loss: 0.8188 - val_accuracy: 0.5591\n",
            "Epoch 9/100\n",
            "2599/2606 [============================>.] - ETA: 0s - loss: 0.8158 - accuracy: 0.5739\n",
            "Epoch 9: val_loss did not improve from 0.81617\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.8157 - accuracy: 0.5739 - val_loss: 0.8312 - val_accuracy: 0.5801\n",
            "Epoch 10/100\n",
            "2606/2606 [==============================] - ETA: 0s - loss: 0.8087 - accuracy: 0.5787\n",
            "Epoch 10: val_loss improved from 0.81617 to 0.80197, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.8087 - accuracy: 0.5787 - val_loss: 0.8020 - val_accuracy: 0.5818\n",
            "Epoch 11/100\n",
            "2602/2606 [============================>.] - ETA: 0s - loss: 0.8063 - accuracy: 0.5818\n",
            "Epoch 11: val_loss improved from 0.80197 to 0.80078, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.8062 - accuracy: 0.5818 - val_loss: 0.8008 - val_accuracy: 0.5863\n",
            "Epoch 12/100\n",
            "2593/2606 [============================>.] - ETA: 0s - loss: 0.8030 - accuracy: 0.5846\n",
            "Epoch 12: val_loss did not improve from 0.80078\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.8032 - accuracy: 0.5845 - val_loss: 0.8306 - val_accuracy: 0.5625\n",
            "Epoch 13/100\n",
            "2598/2606 [============================>.] - ETA: 0s - loss: 0.8025 - accuracy: 0.5842\n",
            "Epoch 13: val_loss improved from 0.80078 to 0.79133, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.8023 - accuracy: 0.5843 - val_loss: 0.7913 - val_accuracy: 0.5969\n",
            "Epoch 14/100\n",
            "2606/2606 [==============================] - ETA: 0s - loss: 0.7983 - accuracy: 0.5898\n",
            "Epoch 14: val_loss did not improve from 0.79133\n",
            "2606/2606 [==============================] - 11s 4ms/step - loss: 0.7983 - accuracy: 0.5898 - val_loss: 0.7950 - val_accuracy: 0.5787\n",
            "Epoch 15/100\n",
            "2595/2606 [============================>.] - ETA: 0s - loss: 0.7974 - accuracy: 0.5911\n",
            "Epoch 15: val_loss did not improve from 0.79133\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.7973 - accuracy: 0.5911 - val_loss: 0.7927 - val_accuracy: 0.5815\n",
            "Epoch 16/100\n",
            "2600/2606 [============================>.] - ETA: 0s - loss: 0.7969 - accuracy: 0.5911\n",
            "Epoch 16: val_loss improved from 0.79133 to 0.78990, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.7970 - accuracy: 0.5911 - val_loss: 0.7899 - val_accuracy: 0.5992\n",
            "Epoch 17/100\n",
            "2605/2606 [============================>.] - ETA: 0s - loss: 0.7942 - accuracy: 0.5959\n",
            "Epoch 17: val_loss improved from 0.78990 to 0.78521, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.7942 - accuracy: 0.5959 - val_loss: 0.7852 - val_accuracy: 0.6069\n",
            "Epoch 18/100\n",
            "2601/2606 [============================>.] - ETA: 0s - loss: 0.7925 - accuracy: 0.5969\n",
            "Epoch 18: val_loss did not improve from 0.78521\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7924 - accuracy: 0.5969 - val_loss: 0.7867 - val_accuracy: 0.6050\n",
            "Epoch 19/100\n",
            "2606/2606 [==============================] - ETA: 0s - loss: 0.7900 - accuracy: 0.5980\n",
            "Epoch 19: val_loss improved from 0.78521 to 0.78303, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.7900 - accuracy: 0.5980 - val_loss: 0.7830 - val_accuracy: 0.6062\n",
            "Epoch 20/100\n",
            "2600/2606 [============================>.] - ETA: 0s - loss: 0.7892 - accuracy: 0.5999\n",
            "Epoch 20: val_loss improved from 0.78303 to 0.78181, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 11s 4ms/step - loss: 0.7892 - accuracy: 0.5999 - val_loss: 0.7818 - val_accuracy: 0.5990\n",
            "Epoch 21/100\n",
            "2606/2606 [==============================] - ETA: 0s - loss: 0.7876 - accuracy: 0.6010\n",
            "Epoch 21: val_loss did not improve from 0.78181\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.7876 - accuracy: 0.6010 - val_loss: 0.7882 - val_accuracy: 0.6087\n",
            "Epoch 22/100\n",
            "2596/2606 [============================>.] - ETA: 0s - loss: 0.7854 - accuracy: 0.6025\n",
            "Epoch 22: val_loss improved from 0.78181 to 0.77489, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7855 - accuracy: 0.6024 - val_loss: 0.7749 - val_accuracy: 0.6128\n",
            "Epoch 23/100\n",
            "2606/2606 [==============================] - ETA: 0s - loss: 0.7845 - accuracy: 0.6024\n",
            "Epoch 23: val_loss did not improve from 0.77489\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7845 - accuracy: 0.6024 - val_loss: 0.8380 - val_accuracy: 0.5751\n",
            "Epoch 24/100\n",
            "2601/2606 [============================>.] - ETA: 0s - loss: 0.7821 - accuracy: 0.6037\n",
            "Epoch 24: val_loss did not improve from 0.77489\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7821 - accuracy: 0.6037 - val_loss: 0.7850 - val_accuracy: 0.5979\n",
            "Epoch 25/100\n",
            "2605/2606 [============================>.] - ETA: 0s - loss: 0.7826 - accuracy: 0.6032\n",
            "Epoch 25: val_loss did not improve from 0.77489\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7826 - accuracy: 0.6032 - val_loss: 0.7981 - val_accuracy: 0.5988\n",
            "Epoch 26/100\n",
            "2603/2606 [============================>.] - ETA: 0s - loss: 0.7812 - accuracy: 0.6059\n",
            "Epoch 26: val_loss improved from 0.77489 to 0.76874, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.7812 - accuracy: 0.6059 - val_loss: 0.7687 - val_accuracy: 0.6129\n",
            "Epoch 27/100\n",
            "2603/2606 [============================>.] - ETA: 0s - loss: 0.7804 - accuracy: 0.6052\n",
            "Epoch 27: val_loss did not improve from 0.76874\n",
            "2606/2606 [==============================] - 11s 4ms/step - loss: 0.7804 - accuracy: 0.6052 - val_loss: 0.7942 - val_accuracy: 0.5873\n",
            "Epoch 28/100\n",
            "2596/2606 [============================>.] - ETA: 0s - loss: 0.7789 - accuracy: 0.6084\n",
            "Epoch 28: val_loss did not improve from 0.76874\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.7789 - accuracy: 0.6084 - val_loss: 0.7701 - val_accuracy: 0.6083\n",
            "Epoch 29/100\n",
            "2596/2606 [============================>.] - ETA: 0s - loss: 0.7803 - accuracy: 0.6073\n",
            "Epoch 29: val_loss did not improve from 0.76874\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7804 - accuracy: 0.6074 - val_loss: 0.7732 - val_accuracy: 0.6118\n",
            "Epoch 30/100\n",
            "2594/2606 [============================>.] - ETA: 0s - loss: 0.7770 - accuracy: 0.6082\n",
            "Epoch 30: val_loss did not improve from 0.76874\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7771 - accuracy: 0.6082 - val_loss: 0.7755 - val_accuracy: 0.6118\n",
            "Epoch 31/100\n",
            "2604/2606 [============================>.] - ETA: 0s - loss: 0.7761 - accuracy: 0.6110\n",
            "Epoch 31: val_loss did not improve from 0.76874\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7761 - accuracy: 0.6110 - val_loss: 0.7706 - val_accuracy: 0.6160\n",
            "Epoch 32/100\n",
            "2598/2606 [============================>.] - ETA: 0s - loss: 0.7759 - accuracy: 0.6098\n",
            "Epoch 32: val_loss did not improve from 0.76874\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.7759 - accuracy: 0.6098 - val_loss: 0.7836 - val_accuracy: 0.6009\n",
            "Epoch 33/100\n",
            "2596/2606 [============================>.] - ETA: 0s - loss: 0.7728 - accuracy: 0.6112\n",
            "Epoch 33: val_loss did not improve from 0.76874\n",
            "2606/2606 [==============================] - 11s 4ms/step - loss: 0.7731 - accuracy: 0.6110 - val_loss: 0.7846 - val_accuracy: 0.6034\n",
            "Epoch 34/100\n",
            "2595/2606 [============================>.] - ETA: 0s - loss: 0.7754 - accuracy: 0.6103\n",
            "Epoch 34: val_loss did not improve from 0.76874\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.7754 - accuracy: 0.6104 - val_loss: 0.7735 - val_accuracy: 0.6176\n",
            "Epoch 35/100\n",
            "2605/2606 [============================>.] - ETA: 0s - loss: 0.7728 - accuracy: 0.6119\n",
            "Epoch 35: val_loss did not improve from 0.76874\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7728 - accuracy: 0.6119 - val_loss: 0.7812 - val_accuracy: 0.6035\n",
            "Epoch 36/100\n",
            "2604/2606 [============================>.] - ETA: 0s - loss: 0.7739 - accuracy: 0.6119\n",
            "Epoch 36: val_loss improved from 0.76874 to 0.76569, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 15s 6ms/step - loss: 0.7739 - accuracy: 0.6119 - val_loss: 0.7657 - val_accuracy: 0.6163\n",
            "Epoch 37/100\n",
            "2606/2606 [==============================] - ETA: 0s - loss: 0.7726 - accuracy: 0.6130\n",
            "Epoch 37: val_loss did not improve from 0.76569\n",
            "2606/2606 [==============================] - 14s 5ms/step - loss: 0.7726 - accuracy: 0.6130 - val_loss: 0.7664 - val_accuracy: 0.6176\n",
            "Epoch 38/100\n",
            "2604/2606 [============================>.] - ETA: 0s - loss: 0.7724 - accuracy: 0.6141\n",
            "Epoch 38: val_loss improved from 0.76569 to 0.76195, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7725 - accuracy: 0.6141 - val_loss: 0.7620 - val_accuracy: 0.6245\n",
            "Epoch 39/100\n",
            "2600/2606 [============================>.] - ETA: 0s - loss: 0.7703 - accuracy: 0.6142\n",
            "Epoch 39: val_loss did not improve from 0.76195\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7703 - accuracy: 0.6141 - val_loss: 0.7794 - val_accuracy: 0.6085\n",
            "Epoch 40/100\n",
            "2601/2606 [============================>.] - ETA: 0s - loss: 0.7693 - accuracy: 0.6155\n",
            "Epoch 40: val_loss did not improve from 0.76195\n",
            "2606/2606 [==============================] - 11s 4ms/step - loss: 0.7693 - accuracy: 0.6154 - val_loss: 0.7740 - val_accuracy: 0.6116\n",
            "Epoch 41/100\n",
            "2606/2606 [==============================] - ETA: 0s - loss: 0.7692 - accuracy: 0.6144\n",
            "Epoch 41: val_loss did not improve from 0.76195\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7692 - accuracy: 0.6144 - val_loss: 0.7855 - val_accuracy: 0.6055\n",
            "Epoch 42/100\n",
            "2602/2606 [============================>.] - ETA: 0s - loss: 0.7691 - accuracy: 0.6147\n",
            "Epoch 42: val_loss did not improve from 0.76195\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7689 - accuracy: 0.6148 - val_loss: 0.7785 - val_accuracy: 0.6116\n",
            "Epoch 43/100\n",
            "2598/2606 [============================>.] - ETA: 0s - loss: 0.7694 - accuracy: 0.6153\n",
            "Epoch 43: val_loss improved from 0.76195 to 0.76179, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7694 - accuracy: 0.6153 - val_loss: 0.7618 - val_accuracy: 0.6191\n",
            "Epoch 44/100\n",
            "2594/2606 [============================>.] - ETA: 0s - loss: 0.7675 - accuracy: 0.6163\n",
            "Epoch 44: val_loss did not improve from 0.76179\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7675 - accuracy: 0.6163 - val_loss: 0.7619 - val_accuracy: 0.6218\n",
            "Epoch 45/100\n",
            "2605/2606 [============================>.] - ETA: 0s - loss: 0.7662 - accuracy: 0.6172\n",
            "Epoch 45: val_loss improved from 0.76179 to 0.75909, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7662 - accuracy: 0.6173 - val_loss: 0.7591 - val_accuracy: 0.6168\n",
            "Epoch 46/100\n",
            "2606/2606 [==============================] - ETA: 0s - loss: 0.7678 - accuracy: 0.6156\n",
            "Epoch 46: val_loss did not improve from 0.75909\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.7678 - accuracy: 0.6156 - val_loss: 0.7721 - val_accuracy: 0.6074\n",
            "Epoch 47/100\n",
            "2606/2606 [==============================] - ETA: 0s - loss: 0.7659 - accuracy: 0.6172\n",
            "Epoch 47: val_loss did not improve from 0.75909\n",
            "2606/2606 [==============================] - 11s 4ms/step - loss: 0.7659 - accuracy: 0.6172 - val_loss: 0.7814 - val_accuracy: 0.6007\n",
            "Epoch 48/100\n",
            "2599/2606 [============================>.] - ETA: 0s - loss: 0.7646 - accuracy: 0.6180\n",
            "Epoch 48: val_loss improved from 0.75909 to 0.75408, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.7649 - accuracy: 0.6179 - val_loss: 0.7541 - val_accuracy: 0.6259\n",
            "Epoch 49/100\n",
            "2604/2606 [============================>.] - ETA: 0s - loss: 0.7650 - accuracy: 0.6170\n",
            "Epoch 49: val_loss did not improve from 0.75408\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7650 - accuracy: 0.6170 - val_loss: 0.7645 - val_accuracy: 0.6176\n",
            "Epoch 50/100\n",
            "2604/2606 [============================>.] - ETA: 0s - loss: 0.7653 - accuracy: 0.6173\n",
            "Epoch 50: val_loss did not improve from 0.75408\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7653 - accuracy: 0.6173 - val_loss: 0.7555 - val_accuracy: 0.6267\n",
            "Epoch 51/100\n",
            "2604/2606 [============================>.] - ETA: 0s - loss: 0.7617 - accuracy: 0.6194\n",
            "Epoch 51: val_loss improved from 0.75408 to 0.74879, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7617 - accuracy: 0.6194 - val_loss: 0.7488 - val_accuracy: 0.6278\n",
            "Epoch 52/100\n",
            "2606/2606 [==============================] - ETA: 0s - loss: 0.7602 - accuracy: 0.6204\n",
            "Epoch 52: val_loss improved from 0.74879 to 0.74730, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7602 - accuracy: 0.6204 - val_loss: 0.7473 - val_accuracy: 0.6316\n",
            "Epoch 53/100\n",
            "2606/2606 [==============================] - ETA: 0s - loss: 0.7629 - accuracy: 0.6191\n",
            "Epoch 53: val_loss did not improve from 0.74730\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7629 - accuracy: 0.6191 - val_loss: 0.7508 - val_accuracy: 0.6256\n",
            "Epoch 54/100\n",
            "2605/2606 [============================>.] - ETA: 0s - loss: 0.7603 - accuracy: 0.6200\n",
            "Epoch 54: val_loss did not improve from 0.74730\n",
            "2606/2606 [==============================] - 11s 4ms/step - loss: 0.7603 - accuracy: 0.6200 - val_loss: 0.7567 - val_accuracy: 0.6307\n",
            "Epoch 55/100\n",
            "2604/2606 [============================>.] - ETA: 0s - loss: 0.7614 - accuracy: 0.6195\n",
            "Epoch 55: val_loss did not improve from 0.74730\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7614 - accuracy: 0.6195 - val_loss: 0.7575 - val_accuracy: 0.6221\n",
            "Epoch 56/100\n",
            "2602/2606 [============================>.] - ETA: 0s - loss: 0.7584 - accuracy: 0.6222\n",
            "Epoch 56: val_loss did not improve from 0.74730\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7584 - accuracy: 0.6222 - val_loss: 0.7634 - val_accuracy: 0.6200\n",
            "Epoch 57/100\n",
            "2594/2606 [============================>.] - ETA: 0s - loss: 0.7564 - accuracy: 0.6227\n",
            "Epoch 57: val_loss did not improve from 0.74730\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7564 - accuracy: 0.6227 - val_loss: 0.7539 - val_accuracy: 0.6272\n",
            "Epoch 58/100\n",
            "2600/2606 [============================>.] - ETA: 0s - loss: 0.7572 - accuracy: 0.6228\n",
            "Epoch 58: val_loss did not improve from 0.74730\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7572 - accuracy: 0.6228 - val_loss: 0.7611 - val_accuracy: 0.6239\n",
            "Epoch 59/100\n",
            "2605/2606 [============================>.] - ETA: 0s - loss: 0.7549 - accuracy: 0.6248\n",
            "Epoch 59: val_loss did not improve from 0.74730\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.7549 - accuracy: 0.6248 - val_loss: 0.7518 - val_accuracy: 0.6267\n",
            "Epoch 60/100\n",
            "2602/2606 [============================>.] - ETA: 0s - loss: 0.7571 - accuracy: 0.6235\n",
            "Epoch 60: val_loss did not improve from 0.74730\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.7570 - accuracy: 0.6235 - val_loss: 0.7652 - val_accuracy: 0.6163\n",
            "Epoch 61/100\n",
            "2600/2606 [============================>.] - ETA: 0s - loss: 0.7559 - accuracy: 0.6240\n",
            "Epoch 61: val_loss did not improve from 0.74730\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.7559 - accuracy: 0.6240 - val_loss: 0.7532 - val_accuracy: 0.6256\n",
            "Epoch 62/100\n",
            "2599/2606 [============================>.] - ETA: 0s - loss: 0.7543 - accuracy: 0.6261\n",
            "Epoch 62: val_loss improved from 0.74730 to 0.74406, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7543 - accuracy: 0.6260 - val_loss: 0.7441 - val_accuracy: 0.6339\n",
            "Epoch 63/100\n",
            "2595/2606 [============================>.] - ETA: 0s - loss: 0.7565 - accuracy: 0.6239\n",
            "Epoch 63: val_loss did not improve from 0.74406\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.7564 - accuracy: 0.6238 - val_loss: 0.7443 - val_accuracy: 0.6332\n",
            "Epoch 64/100\n",
            "2606/2606 [==============================] - ETA: 0s - loss: 0.7541 - accuracy: 0.6265\n",
            "Epoch 64: val_loss did not improve from 0.74406\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.7541 - accuracy: 0.6265 - val_loss: 0.7506 - val_accuracy: 0.6259\n",
            "Epoch 65/100\n",
            "2602/2606 [============================>.] - ETA: 0s - loss: 0.7531 - accuracy: 0.6261\n",
            "Epoch 65: val_loss did not improve from 0.74406\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.7531 - accuracy: 0.6260 - val_loss: 0.7596 - val_accuracy: 0.6166\n",
            "Epoch 66/100\n",
            "2595/2606 [============================>.] - ETA: 0s - loss: 0.7519 - accuracy: 0.6265\n",
            "Epoch 66: val_loss did not improve from 0.74406\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7520 - accuracy: 0.6264 - val_loss: 0.7571 - val_accuracy: 0.6262\n",
            "Epoch 67/100\n",
            "2602/2606 [============================>.] - ETA: 0s - loss: 0.7498 - accuracy: 0.6290\n",
            "Epoch 67: val_loss did not improve from 0.74406\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7498 - accuracy: 0.6290 - val_loss: 0.7500 - val_accuracy: 0.6269\n",
            "Epoch 68/100\n",
            "2603/2606 [============================>.] - ETA: 0s - loss: 0.7515 - accuracy: 0.6282\n",
            "Epoch 68: val_loss improved from 0.74406 to 0.74231, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.7515 - accuracy: 0.6281 - val_loss: 0.7423 - val_accuracy: 0.6338\n",
            "Epoch 69/100\n",
            "2605/2606 [============================>.] - ETA: 0s - loss: 0.7500 - accuracy: 0.6277\n",
            "Epoch 69: val_loss did not improve from 0.74231\n",
            "2606/2606 [==============================] - 12s 5ms/step - loss: 0.7500 - accuracy: 0.6278 - val_loss: 0.7471 - val_accuracy: 0.6335\n",
            "Epoch 70/100\n",
            "2605/2606 [============================>.] - ETA: 0s - loss: 0.7502 - accuracy: 0.6297\n",
            "Epoch 70: val_loss did not improve from 0.74231\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7503 - accuracy: 0.6296 - val_loss: 0.7586 - val_accuracy: 0.6199\n",
            "Epoch 71/100\n",
            "2601/2606 [============================>.] - ETA: 0s - loss: 0.7497 - accuracy: 0.6292\n",
            "Epoch 71: val_loss did not improve from 0.74231\n",
            "2606/2606 [==============================] - 11s 4ms/step - loss: 0.7497 - accuracy: 0.6292 - val_loss: 0.7468 - val_accuracy: 0.6307\n",
            "Epoch 72/100\n",
            "2603/2606 [============================>.] - ETA: 0s - loss: 0.7506 - accuracy: 0.6270\n",
            "Epoch 72: val_loss did not improve from 0.74231\n",
            "2606/2606 [==============================] - 16s 6ms/step - loss: 0.7506 - accuracy: 0.6269 - val_loss: 0.7861 - val_accuracy: 0.5747\n",
            "Epoch 73/100\n",
            "2604/2606 [============================>.] - ETA: 0s - loss: 0.7495 - accuracy: 0.6282\n",
            "Epoch 73: val_loss did not improve from 0.74231\n",
            "2606/2606 [==============================] - 15s 6ms/step - loss: 0.7495 - accuracy: 0.6282 - val_loss: 0.7480 - val_accuracy: 0.6293\n",
            "Epoch 74/100\n",
            "2604/2606 [============================>.] - ETA: 0s - loss: 0.7481 - accuracy: 0.6286\n",
            "Epoch 74: val_loss did not improve from 0.74231\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7481 - accuracy: 0.6287 - val_loss: 0.7428 - val_accuracy: 0.6317\n",
            "Epoch 75/100\n",
            "2603/2606 [============================>.] - ETA: 0s - loss: 0.7488 - accuracy: 0.6306\n",
            "Epoch 75: val_loss did not improve from 0.74231\n",
            "2606/2606 [==============================] - 14s 5ms/step - loss: 0.7488 - accuracy: 0.6306 - val_loss: 0.7824 - val_accuracy: 0.6276\n",
            "Epoch 76/100\n",
            "2603/2606 [============================>.] - ETA: 0s - loss: 0.7497 - accuracy: 0.6281\n",
            "Epoch 76: val_loss improved from 0.74231 to 0.73640, saving model to weights.hdf5\n",
            "2606/2606 [==============================] - 14s 5ms/step - loss: 0.7498 - accuracy: 0.6280 - val_loss: 0.7364 - val_accuracy: 0.6397\n",
            "Epoch 77/100\n",
            "2603/2606 [============================>.] - ETA: 0s - loss: 0.7472 - accuracy: 0.6299\n",
            "Epoch 77: val_loss did not improve from 0.73640\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7473 - accuracy: 0.6299 - val_loss: 0.7692 - val_accuracy: 0.6141\n",
            "Epoch 78/100\n",
            "2605/2606 [============================>.] - ETA: 0s - loss: 0.7485 - accuracy: 0.6303\n",
            "Epoch 78: val_loss did not improve from 0.73640\n",
            "2606/2606 [==============================] - 14s 5ms/step - loss: 0.7485 - accuracy: 0.6303 - val_loss: 0.7543 - val_accuracy: 0.6147\n",
            "Epoch 79/100\n",
            "2602/2606 [============================>.] - ETA: 0s - loss: 0.7467 - accuracy: 0.6323\n",
            "Epoch 79: val_loss did not improve from 0.73640\n",
            "2606/2606 [==============================] - 14s 5ms/step - loss: 0.7466 - accuracy: 0.6323 - val_loss: 0.7628 - val_accuracy: 0.6204\n",
            "Epoch 80/100\n",
            "2600/2606 [============================>.] - ETA: 0s - loss: 0.7448 - accuracy: 0.6332\n",
            "Epoch 80: val_loss did not improve from 0.73640\n",
            "2606/2606 [==============================] - 14s 5ms/step - loss: 0.7449 - accuracy: 0.6331 - val_loss: 0.7460 - val_accuracy: 0.6317\n",
            "Epoch 81/100\n",
            "2606/2606 [==============================] - ETA: 0s - loss: 0.7465 - accuracy: 0.6318\n",
            "Epoch 81: val_loss did not improve from 0.73640\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7465 - accuracy: 0.6318 - val_loss: 0.7816 - val_accuracy: 0.5892\n",
            "Epoch 82/100\n",
            "2605/2606 [============================>.] - ETA: 0s - loss: 0.7439 - accuracy: 0.6335\n",
            "Epoch 82: val_loss did not improve from 0.73640\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7439 - accuracy: 0.6335 - val_loss: 0.7466 - val_accuracy: 0.6292\n",
            "Epoch 83/100\n",
            "2606/2606 [==============================] - ETA: 0s - loss: 0.7451 - accuracy: 0.6320\n",
            "Epoch 83: val_loss did not improve from 0.73640\n",
            "2606/2606 [==============================] - 15s 6ms/step - loss: 0.7451 - accuracy: 0.6320 - val_loss: 0.7576 - val_accuracy: 0.6203\n",
            "Epoch 84/100\n",
            "2603/2606 [============================>.] - ETA: 0s - loss: 0.7462 - accuracy: 0.6303\n",
            "Epoch 84: val_loss did not improve from 0.73640\n",
            "2606/2606 [==============================] - 17s 6ms/step - loss: 0.7462 - accuracy: 0.6304 - val_loss: 0.7378 - val_accuracy: 0.6368\n",
            "Epoch 85/100\n",
            "2596/2606 [============================>.] - ETA: 0s - loss: 0.7425 - accuracy: 0.6356\n",
            "Epoch 85: val_loss did not improve from 0.73640\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7426 - accuracy: 0.6356 - val_loss: 0.7613 - val_accuracy: 0.6210\n",
            "Epoch 86/100\n",
            "2598/2606 [============================>.] - ETA: 0s - loss: 0.7450 - accuracy: 0.6348\n",
            "Epoch 86: val_loss did not improve from 0.73640\n",
            "2606/2606 [==============================] - 14s 5ms/step - loss: 0.7448 - accuracy: 0.6349 - val_loss: 0.7380 - val_accuracy: 0.6387\n",
            "Epoch 87/100\n",
            "2599/2606 [============================>.] - ETA: 0s - loss: 0.7426 - accuracy: 0.6338\n",
            "Epoch 87: val_loss did not improve from 0.73640\n",
            "2606/2606 [==============================] - 13s 5ms/step - loss: 0.7425 - accuracy: 0.6338 - val_loss: 0.7408 - val_accuracy: 0.6378\n",
            "Epoch 88/100\n",
            "2605/2606 [============================>.] - ETA: 0s - loss: 0.7429 - accuracy: 0.6353\n",
            "Epoch 88: val_loss did not improve from 0.73640\n",
            "2606/2606 [==============================] - 14s 6ms/step - loss: 0.7428 - accuracy: 0.6353 - val_loss: 0.7454 - val_accuracy: 0.6333\n",
            "Epoch 89/100\n",
            "2605/2606 [============================>.] - ETA: 0s - loss: 0.7446 - accuracy: 0.6340\n",
            "Epoch 89: val_loss did not improve from 0.73640\n",
            "2606/2606 [==============================] - 14s 6ms/step - loss: 0.7446 - accuracy: 0.6340 - val_loss: 0.7980 - val_accuracy: 0.5927\n",
            "Epoch 90/100\n",
            "2606/2606 [==============================] - ETA: 0s - loss: 0.7428 - accuracy: 0.6350\n",
            "Epoch 90: val_loss did not improve from 0.73640\n",
            "2606/2606 [==============================] - 15s 6ms/step - loss: 0.7428 - accuracy: 0.6350 - val_loss: 0.7464 - val_accuracy: 0.6347\n",
            "Epoch 91/100\n",
            "2599/2606 [============================>.] - ETA: 0s - loss: 0.7445 - accuracy: 0.6317\n",
            "Epoch 91: val_loss did not improve from 0.73640\n",
            "2606/2606 [==============================] - 15s 6ms/step - loss: 0.7444 - accuracy: 0.6317 - val_loss: 0.7460 - val_accuracy: 0.6257\n",
            "Epoch 92/100\n",
            "2602/2606 [============================>.] - ETA: 0s - loss: 0.7423 - accuracy: 0.6350\n",
            "Epoch 92: val_loss did not improve from 0.73640\n",
            "2606/2606 [==============================] - 15s 6ms/step - loss: 0.7422 - accuracy: 0.6351 - val_loss: 0.7426 - val_accuracy: 0.6346\n",
            "Epoch 92: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(\"weights.hdf5\")"
      ],
      "metadata": {
        "id": "cmDJqcLbyKg3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "predictions_test = model.predict(X_test)\n",
        "dt_time_pred = time.time() - start_time"
      ],
      "metadata": {
        "id": "0367yUaCcjej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd62226d-53af-4660-cc1a-b60121d60895"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1629/1629 [==============================] - 3s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PBa7ZOKeeLD",
        "outputId": "c215d0a8-1175-4cc6-b161-34b494432f9f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.02081234 0.5491795  0.4300082 ]\n",
            " [0.0177356  0.5115659  0.47069845]\n",
            " [0.02229356 0.6843124  0.29339406]\n",
            " ...\n",
            " [0.01263611 0.64244425 0.3449196 ]\n",
            " [0.01183403 0.46602407 0.52214175]\n",
            " [0.15455173 0.7137409  0.1317074 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xA5i3NxR0ThO",
        "outputId": "2e3676d6-2649-43f4-e53b-b8cb1b56a090"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52121, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test = predictions_test.argmax(axis=1)\n",
        "predictions_test "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32tuOhFE0ISP",
        "outputId": "6b8485c2-7d41-4c11-e233-098f58aeb843"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test = predictions_test + 1\n",
        "predictions_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D32c0eXj1HyR",
        "outputId": "b2929379-576d-4fef-9489-d674e2708e87"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, ..., 2, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = y_test.argmax(axis=1)\n",
        "y_test "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAPS-s431Lf5",
        "outputId": "3d7cd352-9d26-4725-c31c-40cbd253191e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 2, 2, 1])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = y_test + 1\n",
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYuiQmy21T7C",
        "outputId": "a3be6e29-0037-4a96-fe70-dc9305a848d6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 2, 2, ..., 3, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Fit Time: {} seconds\".format(dt_time_fit))\n",
        "print(\"Prediction Time: {} seconds\".format(dt_time_pred))\n",
        "print(\"Precision: \", metrics.precision_score(y_test,predictions_test, average='micro'))\n",
        "print(\"Recall: \", metrics.recall_score(y_test,predictions_test,average='micro'))\n",
        "print(\"Accuracy: \", metrics.accuracy_score(y_test,predictions_test))\n",
        "print(\"F1_score: \", metrics.f1_score(y_test,predictions_test, average='micro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNUVT6zddo3O",
        "outputId": "1d577563-300c-492e-a3a1-69b9f40f439b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fit Time: 1184.6432104110718 seconds\n",
            "Prediction Time: 3.461582899093628 seconds\n",
            "Precision:  0.6451142533719614\n",
            "Recall:  0.6451142533719614\n",
            "Accuracy:  0.6451142533719614\n",
            "F1_score:  0.6451142533719614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = confusion_matrix(y_test,predictions_test)\n",
        "cm = pd.DataFrame(data, columns=np.unique(y_test), index = np.unique(y_test))\n",
        "cm.index.name = 'Actual'\n",
        "cm.columns.name = 'Predicted'\n",
        "plt.figure(figsize = (10,7))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", annot_kws={\"size\": 12})\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "RmXhp7CvdCAb",
        "outputId": "9a904817-a76e-4cb8-97f9-a448d4d5f8bb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}